{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libaries\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pb\n",
    "\n",
    "#Initiateing Model and Tokenizer\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GPT-sw3-126m-BaseLargeTunedHyp_3Epoch_myown\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"GPT-sw3-126m-BaseLargeTunedHyp_3Epoch_myown\")\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes away all columns that have less than one procent of its boxes filled. \n",
    "def taBortEnProcent(FromFile, PlaceToSave):\n",
    "    data = pb.read_excel(FromFile)\n",
    "    missing_percentage = (data.isnull().sum() / len(data)) * 100\n",
    "    cols_to_drop = missing_percentage[missing_percentage >= 99].index\n",
    "    data_filtered = data.drop(columns=cols_to_drop)\n",
    "\n",
    "    print(\"Shape after filtering:\", data_filtered.shape)\n",
    "\n",
    "    data_filtered.to_excel(PlaceToSave, index=False)\n",
    "\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formats the input text in the same way as it was trained\n",
    "\n",
    "def formatering(File):\n",
    "\n",
    "    data = File\n",
    "\n",
    "    print(data.shape)\n",
    "\n",
    "    indata = data.iloc[:, 1:].values.tolist()\n",
    "\n",
    "    train_texts, val_and_test_texts = train_test_split(indata, test_size=0.2) \n",
    "    val_texts, test_texts_input = train_test_split(val_and_test_texts, test_size=0.5)\n",
    "\n",
    "\n",
    "    input_texts = [f\"<|endoftext|><s>User: Skriv en patientjornal efter en ultraljudsundersökning utifrån dessa värden: {test_texts_input}<s>Bot:\"\n",
    "                  for test_texts_input in zip(test_texts_input)]\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"test\": input_texts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the leng of the input and takes away tokens if its to long. Then generates a text.\n",
    "\n",
    "def generating(text):\n",
    "    prompt = text.strip()\n",
    "\n",
    "    token_count = len(tokenizer.encode_plus(prompt)[\"input_ids\"])\n",
    "    max_token_count = 2048 - 140\n",
    "\n",
    "    if token_count > max_token_count:\n",
    "        end_index = len(prompt) - 7\n",
    "        end_seq = prompt[end_index:]\n",
    "        tokens = tokenizer.encode_plus(prompt[:end_index])[\"input_ids\"]\n",
    "        tokens = tokens[:max_token_count]\n",
    "        prompt = (tokenizer.decode(tokens) + (end_seq)).strip()\n",
    "    \n",
    "\n",
    "    generator = pipeline('text-generation', tokenizer=tokenizer, model=model, device=device)\n",
    "    generated = generator(prompt, max_new_tokens=140, do_sample=True, temperature=0.47, top_p=1, top_k = 23, repetition_penalty = 1.05)[0][\"generated_text\"]\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process to generate text\n",
    "'''\n",
    "As you can see in the below functione a new file is saved after 1 % have been taken away.\n",
    "So if you alredy have doen this function one time, its more time efficent\n",
    "to just loade the new file directly\n",
    "'''\n",
    "file = taBortEnProcent(\"From_this_file\", \"To_this_file\")\n",
    "\n",
    "test_texter = formatering(file)[\"test\"]\n",
    "idx = 3\n",
    "generated_text = generating(test_texter[idx])\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
