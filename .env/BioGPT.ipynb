{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\KEX\\.env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'COVID-19 is still an ongoing pandemic.'},\n",
       " {'generated_text': 'COVID-19 is a worldwide pandemic that continues to spread around the globe.'},\n",
       " {'generated_text': 'COVID-19 is caused by a novel coronavirus.'},\n",
       " {'generated_text': 'COVID-19 is becoming more and more prevalent all over the world.'},\n",
       " {'generated_text': 'COVID-19 is associated with an increase in risk of cardiovascular disease events, suggesting an association between increased'},\n",
       " {'generated_text': 'COVID-19 is considered a pandemic with new challenges.'},\n",
       " {'generated_text': 'COVID-19 is likely a good choice.'}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "from transformers import BioGptTokenizer, BioGptForCausalLM\n",
    "tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\n",
    "model = BioGptForCausalLM.from_pretrained(\"microsoft/biogpt\")\n",
    "text = \"Covid-19 is\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "set_seed(42)\n",
    "generator(\"COVID-19 is\", max_length=20, num_return_sequences=5, do_sample=True, truncation=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stomach Pain: A Case Report and Review of the Literature on the Diagnosis and Treatment of Gastroesophageal Reflux Disease and Gastroesophageal Reflux Disease-Related Symptoms. (Part 2). (2). (3). (4). (5). (6.) (7.) (8.) (9.) (10.) (11.) (12.) (13.) (14.) (15.) (16.) (17.) (18.) (19.) (20.) (21.) (22.) (23.) (24.) (25.) (26.) (27.) (27.) (28.) (28.) (28.) (29.) (29.) (30.) (31.) (32.) (32.) (32.) (33.) (34.) (34.) (34.) (35.) (36.) (37.) (37.) (36.) (37.) (37.) (37.) (39.) (40.) (40.) (41.) (41.) (41.) (41.) (41.) (41.) (41.) (41.) (41.) (41.) (41.) (41.) (41.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BioGptTokenizer, BioGptForCausalLM, set_seed\n",
    "\n",
    "tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\n",
    "model = BioGptForCausalLM.from_pretrained(\"microsoft/biogpt\")\n",
    "\n",
    "sentence = \"Stomach Pain\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "with torch.no_grad():\n",
    "    beam_output = model.generate(**inputs,\n",
    "                                min_length=100,\n",
    "                                max_length=1024,\n",
    "                                num_beams=5,\n",
    "                                early_stopping=True\n",
    "                                )\n",
    "tokenizer.decode(beam_output[0], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
